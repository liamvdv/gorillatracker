{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports and EmbeddingProjector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from io import BytesIO\n",
    "from pathlib import Path\n",
    "from bokeh.io import output_notebook\n",
    "from bokeh.resources import INLINE\n",
    "from gorillatracker.scripts.visualize_embeddings import EmbeddingProjector\n",
    "import pandas as pd\n",
    "from gorillatracker.utils import embedding_generator\n",
    "from gorillatracker.data.nlet import NletDataModule, build_onelet, SupervisedDataset\n",
    "from gorillatracker.utils import wandb_loader\n",
    "from torchvision.transforms import Compose, Normalize, Resize\n",
    "import torch\n",
    "\n",
    "output_notebook(INLINE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WANDB_RUN = \"https://wandb.ai/gorillas/Embedding-ResNet18-CXL-OpenSet/runs/zz3w8cmw\"\n",
    "DATA_DIR = Path(\n",
    "    \"/workspaces/gorillatracker/data/splits/ground_truth-cxl-face_images-openset-reid-val-0-test-0-mintraincount-3-seed-42-train-50-val-25-test-25\"\n",
    ")\n",
    "DATASET_CLS = SupervisedDataset\n",
    "\n",
    "model = wandb_loader.get_model_for_run_url(WANDB_RUN)\n",
    "# model = SwinV2BaseWrapper.load_from_checkpoint(\n",
    "#     \"/workspaces/gorillatracker/logs/Embedding-SwinV2-SSL-Face/0yxdvoav/checkpoints/last_model_ckpt.ckpt\",\n",
    "#     data_module=None,\n",
    "#     wandb_run=None,\n",
    "# )\n",
    "resize = getattr(model, \"data_resize_transform\", (192, 192))\n",
    "model_transforms = Resize(resize)\n",
    "normalize_transform = Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "use_normalization = getattr(model, \"use_normalization\", True)\n",
    "if use_normalization:\n",
    "    model_transforms = Compose([model_transforms, normalize_transform])\n",
    "\n",
    "\n",
    "data_module = NletDataModule(\n",
    "    data_dir=DATA_DIR,\n",
    "    dataset_class=DATASET_CLS,\n",
    "    nlet_builder=build_onelet,\n",
    "    batch_size=128,\n",
    "    workers=10,\n",
    "    model_transforms=model_transforms,\n",
    "    training_transforms=lambda x: x,\n",
    "    dataset_names=[\"Inference\"],\n",
    ")\n",
    "\n",
    "data_module.setup(\"validate\")\n",
    "\n",
    "raw_predictions = embedding_generator.generate_embeddings(model, data_module.val_dataloader()[0])\n",
    "df = embedding_generator.df_from_predictions(raw_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bokeh.plotting import output_file, show\n",
    "from PIL import Image\n",
    "import base64\n",
    "\n",
    "embeddings = df[\"embedding\"].values\n",
    "embeddings = np.array([embedding.cpu().numpy() for embedding in embeddings])\n",
    "\n",
    "\n",
    "images: list[str] = []\n",
    "images = []\n",
    "for id in df[\"id\"]:\n",
    "    image = Image.open(id)\n",
    "    # base64.b64encode(buffer.getvalue()).decode(\"utf-8\")\n",
    "    buffer = BytesIO()\n",
    "    image.save(buffer, format=\"JPEG\")\n",
    "    img_str = base64.b64encode(buffer.getvalue()).decode(\"utf-8\")\n",
    "    images.append(img_str)\n",
    "\n",
    "\n",
    "ep = EmbeddingProjector()\n",
    "low_dim_embeddings = ep.reduce_dimensions(embeddings, method=\"tsne\")\n",
    "fig = ep.plot_clusters(\n",
    "    low_dim_embeddings, df[\"label\"], df[\"label_string\"], images , title=\"Embedding Projector\", figsize=(12, 10)\n",
    ")\n",
    "output_file(filename=\"embedding.html\")\n",
    "show(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Local viewing of missclassified images (df from last executed cell of one of the above is used)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchmetrics.functional import pairwise_euclidean_distance\n",
    "import matplotlib.pyplot as plt\n",
    "import ipywidgets as widgets\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "def get_closest_indices(embeddings: torch.Tensor, k: int) -> torch.Tensor:\n",
    "    distance_matrix = pairwise_euclidean_distance(embeddings)\n",
    "    distance_matrix.fill_diagonal_(float(\"inf\"))\n",
    "    # Find the indices of the closest embeddings for each embedding\n",
    "    closest_indices = []\n",
    "    distances = []\n",
    "    for i in range(len(embeddings)):\n",
    "        closest_indices_i = torch.argsort(distance_matrix[i])[:k].tolist()\n",
    "        distances.append([distance_matrix[ci][i] for ci in closest_indices_i])\n",
    "        closest_indices.append(closest_indices_i)\n",
    "\n",
    "    return closest_indices, distances\n",
    "\n",
    "\n",
    "def get_missclassified_images(embeddings_table: pd.DataFrame, k: int) -> None:\n",
    "    misclassified_images = []\n",
    "    misclassified_distances = []\n",
    "    labels = embeddings_table[\"label\"]\n",
    "    embeddings = embeddings_table[\"embedding\"].to_numpy()\n",
    "    embeddings = torch.stack(embeddings.tolist())\n",
    "    closest_indices, distances = get_closest_indices(torch.tensor(embeddings), k)\n",
    "    counter = 0\n",
    "    for i in range(len(labels)):\n",
    "        true_label = labels[i]\n",
    "        nearest_labels = []\n",
    "        for j in range(k):\n",
    "            nearest_labels.append(labels[closest_indices[i][j]])\n",
    "        predicted_label = max(nearest_labels, key=nearest_labels.count)\n",
    "        if true_label != predicted_label:\n",
    "            misclassified_images.append((i, *closest_indices[i]))\n",
    "            misclassified_distances.append((i, *distances[i]))\n",
    "            counter += 1\n",
    "\n",
    "    print(f\"Accuracy: {1 - counter / len(labels)}\")\n",
    "\n",
    "    return misclassified_images, misclassified_distances\n",
    "\n",
    "\n",
    "k = 3  # number of closest images to display\n",
    "compare_amount = 4  # amount of images to compare for each missclassified image\n",
    "missclassified, distances = get_missclassified_images(df, k)\n",
    "images_per_page = k + 1\n",
    "\n",
    "labels = df[\"label_string\"]\n",
    "images = []\n",
    "for id in df[\"id\"]:\n",
    "    image = Image.open(id)\n",
    "    images.append(image)\n",
    "\n",
    "height_ratios = [0.3 for _ in range(compare_amount)]\n",
    "height_ratios.insert(0, 0.4)\n",
    "\n",
    "scale_factor = 2.5 # Scale factor for the height of the subplots\n",
    "\n",
    "# Function to display a page of images\n",
    "def display_images(page):\n",
    "    start = page\n",
    "    fig, axs = plt.subplots(1 + compare_amount, images_per_page, figsize=(15, (compare_amount+1) * scale_factor), height_ratios=height_ratios)  # Create subplots\n",
    "    \n",
    "    current_labels = []    \n",
    "    for i in range(images_per_page):\n",
    "        if start < len(missclassified):\n",
    "            ind = missclassified[start][i]\n",
    "            axs[0, i].imshow(images[ind])\n",
    "            if i == 0:\n",
    "                axs[0, i].set_title(\"missclassified image (\" + labels[ind] + \")\")\n",
    "            else:\n",
    "                axs[0, i].set_title(str(i) + \". closest image (\" + labels[ind] + \") \\n dist: \" + str(round(distances[start][i].item(), 3)))\n",
    "            current_labels.append((labels[ind], images[ind], df[\"id\"][ind]))\n",
    "            axs[0, i].axis(\"off\")\n",
    "        else:\n",
    "            axs[0, i].axis(\"off\")  # Hide axes for empty subplots\n",
    "    for i in range(images_per_page):\n",
    "        lbl, img, id = current_labels[i]\n",
    "        filtered_df = df[(df['label_string'] == lbl) & (df['id'] != id)].head(compare_amount)\n",
    "        comp_images = []\n",
    "        for id in filtered_df[\"id\"]:\n",
    "            image = Image.open(id)\n",
    "            comp_images.append(image)\n",
    "        for k in range(len(comp_images)):\n",
    "            axs[k + 1, i].imshow(comp_images[k])\n",
    "            axs[k + 1, i].set_title(lbl)\n",
    "            axs[k + 1, i].axis(\"off\")\n",
    "        remainder = compare_amount - len(comp_images)\n",
    "        for k in range(remainder):\n",
    "            axs[k + 1 + len(comp_images), i].axis(\"off\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "page_selector = widgets.IntSlider(min=0, max=(len(missclassified) - 1), description=\"Page:\")\n",
    "widgets.interact(display_images, page=page_selector)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
