{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports and EmbeddingProjector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from io import BytesIO\n",
    "import base64\n",
    "from bokeh.io import output_notebook\n",
    "from bokeh.resources import INLINE\n",
    "from gorillatracker.scripts.visualize_embeddings import EmbeddingProjector\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "output_notebook(INLINE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate embeddings from run (if embedding.pkt exists, this cell is not needed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gorillatracker.utils.embedding_generator import generate_embeddings_from_run\n",
    "from gorillatracker.utils.embedding_generator import read_embeddings_from_disk\n",
    "from PIL import Image\n",
    "\n",
    "df = generate_embeddings_from_run(\"https://wandb.ai/gorillas/Embedding-SwinV2Large-CXL-Open/runs/4nlubzcy/workspace?nw=nwuseremirhan404\", \n",
    "                                  \"embedding.pkl\", \n",
    "                                  \"gorillatracker.datasets.cxl.CXLDataset\", \n",
    "                                  \"/workspaces/gorillatracker/data/splits/ground_truth-cxl-face_images-openset-reid-val-0-test-0-mintraincount-3-seed-42-train-50-val-25-test-25\"\n",
    "                                 )\n",
    "regenerate = True\n",
    "\n",
    "if regenerate:\n",
    "    df = generate_embeddings_from_run(\"https://wandb.ai/gorillas/Embedding-SwinV2-CXL-Open/runs/7wg98d3l/workspace\", \"embedding.pkl\")\n",
    "else:\n",
    "    df = read_embeddings_from_disk(\"embedding.pkl\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gorillatracker.utils.embedding_generator import read_embeddings_from_disk\n",
    "from bokeh.plotting import save, output_file, show\n",
    "df = read_embeddings_from_disk(\"embedding.pkl\")\n",
    "\n",
    "embeddings = df[\"embedding\"].to_numpy()\n",
    "embeddings = np.stack(embeddings)\n",
    "\n",
    "images = []\n",
    "for id in df[\"id\"]:\n",
    "    image = Image.open(id)\n",
    "    buffer = BytesIO()\n",
    "    image.save(buffer, format=\"JPEG\")\n",
    "    image_byte = base64.b64encode(buffer.getvalue()).decode(\"utf-8\")\n",
    "    images.append(image_byte)\n",
    "\n",
    "ep = EmbeddingProjector()\n",
    "low_dim_embeddings = ep.reduce_dimensions(embeddings, method=\"tsne\")\n",
    "fig = ep.plot_clusters(\n",
    "    low_dim_embeddings, df[\"label\"], df[\"label_string\"], images, title=\"Embedding Projector\", figsize=(12, 10)\n",
    ")\n",
    "output_file(filename=\"embedding.html\")\n",
    "show(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Local viewing of missclassified images (df from last executed cell of one of the above is used)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchmetrics.functional import pairwise_euclidean_distance\n",
    "import matplotlib.pyplot as plt\n",
    "import ipywidgets as widgets\n",
    "\n",
    "\n",
    "def get_closest_indices(embeddings: torch.Tensor, k: int) -> torch.Tensor:\n",
    "    distance_matrix = pairwise_euclidean_distance(embeddings)\n",
    "    distance_matrix.fill_diagonal_(float(\"inf\"))\n",
    "    # Find the indices of the closest embeddings for each embedding\n",
    "    closest_indices = []\n",
    "    distances = []\n",
    "    for i in range(len(embeddings)):\n",
    "        closest_indices_i = torch.argsort(distance_matrix[i])[:k].tolist()\n",
    "        distances.append([distance_matrix[ci][i] for ci in closest_indices_i])\n",
    "        closest_indices.append(closest_indices_i)\n",
    "\n",
    "    return closest_indices, distances\n",
    "\n",
    "\n",
    "def get_missclassified_images(embeddings_table: pd.DataFrame, k: int) -> None:\n",
    "    misclassified_images = []\n",
    "    misclassified_distances = []\n",
    "    labels = embeddings_table[\"label\"]\n",
    "    embeddings = embeddings_table[\"embedding\"].to_numpy()\n",
    "    embeddings = torch.stack(embeddings.tolist())\n",
    "    closest_indices, distances = get_closest_indices(torch.tensor(embeddings), k)\n",
    "    counter = 0\n",
    "    for i in range(len(labels)):\n",
    "        true_label = labels[i]\n",
    "        nearest_labels = []\n",
    "        for j in range(k):\n",
    "            nearest_labels.append(labels[closest_indices[i][j]])\n",
    "        predicted_label = max(nearest_labels, key=nearest_labels.count)\n",
    "        if true_label != predicted_label:\n",
    "            misclassified_images.append((i, *closest_indices[i]))\n",
    "            misclassified_distances.append((i, *distances[i]))\n",
    "            counter += 1\n",
    "\n",
    "    print(f\"Accuracy: {1 - counter / len(labels)}\")\n",
    "\n",
    "    return misclassified_images, misclassified_distances\n",
    "\n",
    "\n",
    "k = 3  # number of closest images to display\n",
    "compare_amount = 4  # amount of images to compare for each missclassified image\n",
    "missclassified, distances = get_missclassified_images(df, k)\n",
    "images_per_page = k + 1\n",
    "\n",
    "labels = df[\"label_string\"]\n",
    "images = []\n",
    "for id in df[\"id\"]:\n",
    "    image = Image.open(id)\n",
    "    images.append(image)\n",
    "\n",
    "height_ratios = [0.3 for _ in range(compare_amount)]\n",
    "height_ratios.insert(0, 0.4)\n",
    "\n",
    "scale_factor = 2.5 # Scale factor for the height of the subplots\n",
    "\n",
    "# Function to display a page of images\n",
    "def display_images(page):\n",
    "    start = page\n",
    "    fig, axs = plt.subplots(1 + compare_amount, images_per_page, figsize=(15, (compare_amount+1) * scale_factor), height_ratios=height_ratios)  # Create subplots\n",
    "    \n",
    "    current_labels = []    \n",
    "    for i in range(images_per_page):\n",
    "        if start < len(missclassified):\n",
    "            ind = missclassified[start][i]\n",
    "            axs[0, i].imshow(images[ind])\n",
    "            if i == 0:\n",
    "                axs[0, i].set_title(\"missclassified image (\" + labels[ind] + \")\")\n",
    "            else:\n",
    "                axs[0, i].set_title(str(i) + \". closest image (\" + labels[ind] + \") \\n dist: \" + str(round(distances[start][i].item(), 3)))\n",
    "            current_labels.append((labels[ind], images[ind], df[\"id\"][ind]))\n",
    "            axs[0, i].axis(\"off\")\n",
    "        else:\n",
    "            axs[0, i].axis(\"off\")  # Hide axes for empty subplots\n",
    "    for i in range(images_per_page):\n",
    "        lbl, img, id = current_labels[i]\n",
    "        filtered_df = df[(df['label_string'] == lbl) & (df['id'] != id)].head(compare_amount)\n",
    "        comp_images = []\n",
    "        for id in filtered_df[\"id\"]:\n",
    "            image = Image.open(id)\n",
    "            comp_images.append(image)\n",
    "        for k in range(len(comp_images)):\n",
    "            axs[k + 1, i].imshow(comp_images[k])\n",
    "            axs[k + 1, i].set_title(lbl)\n",
    "            axs[k + 1, i].axis(\"off\")\n",
    "        remainder = compare_amount - len(comp_images)\n",
    "        for k in range(remainder):\n",
    "            axs[k + 1 + len(comp_images), i].axis(\"off\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "page_selector = widgets.IntSlider(min=0, max=(len(missclassified) - 1), description=\"Page:\")\n",
    "widgets.interact(display_images, page=page_selector)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
