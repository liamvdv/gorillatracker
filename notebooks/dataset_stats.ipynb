{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import datetime as dt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_path = \"/workspaces/gorillatracker/datasets/supervised/splits/cxl_bodies_openset_seed42_kfold\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirs = os.listdir(dir_path)\n",
    "print(dirs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a dataframe for each directory\n",
    "df: list[pd.DataFrame] = []\n",
    "\n",
    "for i, d in enumerate(dirs):\n",
    "    data = []\n",
    "    solitary_data = 0\n",
    "    # Extract data from filenames\n",
    "    for filename in os.listdir(os.path.join(dir_path, d)):\n",
    "        parts = filename.split(\"_\")\n",
    "        if len(parts) >= 4:\n",
    "            id_, camid, date, id2 = parts[:4]\n",
    "            solitary = False\n",
    "            if(len(id_) != 4):  # if != 4, then the gorilla is a solitary one without a group\n",
    "                # print(f\"Solitary in {filename}\")\n",
    "                solitary_data += 1\n",
    "                solitary = True\n",
    "            Groupid = id_[:2] if not solitary else \"SOLITARY\"\n",
    "            id_ = id_[2:] if not solitary else \"\".join(filter(str.isdigit, id_))\n",
    "            id2 = id2[:4]\n",
    "            id2 = \"\".join(filter(str.isdigit, id2)) # remove non-numeric characters\n",
    "            date = dt.datetime.strptime(date, \"%Y%m%d\").date()\n",
    "            data.append((Groupid, id_, camid, date, id2, f\"{dir_path}/{d}/{filename}\"))\n",
    "        else:\n",
    "            print(f\"Invalid filename {filename}\")\n",
    "            \n",
    "    # Create a DataFrame\n",
    "    df.append(pd.DataFrame(data, columns=[\"GROUP\", \"ID\", \"CAM\", \"DATE\", \"CLIP_ID\", \"FILENAME\"]))\n",
    "    print(f\"Directory {d} had {solitary_data} images of solitary gorillas with no group\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df[0].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot the Number of Videos per Individual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, d in enumerate(dirs):\n",
    "    print(f\"{d}:\")\n",
    "    print(f\"\\t Images: {df[i].shape[0]}\")\n",
    "    print(f\"\\t Individuals: {df[i].groupby(['GROUP', 'ID']).ngroups}\")\n",
    "    print(f\"\\t Groups: {df[i]['GROUP'].nunique()}\")\n",
    "    print(f\"\\t Cameras: {df[i]['CAM'].nunique()}\")\n",
    "    print(f\"\\t Days: {df[i]['DATE'].nunique()}\")\n",
    "    print(f\"\\t DateRange: {df[i]['DATE'].min()} - {df[i]['DATE'].max()}\")\n",
    "    print(f\"\\t Video_clips: {df[i].groupby(['CAM', 'DATE', 'CLIP_ID']).ngroups}\")\n",
    "    print(f\"\\t Videos: {df[i].groupby(['CAM', 'DATE']).ngroups}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined = pd.concat(df)\n",
    "print(\"Combined:\")\n",
    "print(f\"\\t Images: {len(df_combined)}\")\n",
    "print(f\"\\t Individuals: {df_combined.groupby(['GROUP', 'ID']).ngroups}\")\n",
    "print(f\"\\t Groups: {df_combined['GROUP'].nunique()}\")\n",
    "print(f\"\\t Cameras: {df_combined['CAM'].nunique()}\")\n",
    "print(f\"\\t Days: {df_combined['DATE'].nunique()}\")\n",
    "print(f\"\\t DateRange: {df_combined['DATE'].min()} - {df_combined['DATE'].max()}\")\n",
    "print(f\"\\t Video_clips: {df_combined.groupby(['CAM', 'DATE', 'CLIP_ID']).ngroups}\")\n",
    "print(f\"\\t Videos: {df_combined.groupby(['CAM', 'DATE']).ngroups}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Video Clip Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_videos = df_combined.drop_duplicates(subset=[\"GROUP\", \"ID\", \"CAM\", \"DATE\", \"CLIP_ID\"])\n",
    "videos_per_id = unique_videos.groupby([\"GROUP\", \"ID\"]).size()\n",
    "video_count_distribution = videos_per_id.value_counts().sort_index()\n",
    "\n",
    "plt.figure(figsize=(5, 2))\n",
    "plt.bar(video_count_distribution.index, video_count_distribution.values)\n",
    "plt.xlabel(\"Num Video Clips/ID\")\n",
    "plt.ylabel(\"Individuals\")\n",
    "plt.title(\"Complete DS: Number of Video Clips per ID\")\n",
    "plt.xticks(video_count_distribution.index)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, d in enumerate(dirs):\n",
    "    unique_videos = df[i].drop_duplicates(subset=[\"GROUP\", \"ID\", \"CAM\", \"DATE\", \"CLIP_ID\"])\n",
    "    videos_per_id = unique_videos.groupby([\"GROUP\", \"ID\"]).size()\n",
    "    video_count_distribution = videos_per_id.value_counts().sort_index()\n",
    "    plt.figure(figsize=(5, 2))\n",
    "    plt.bar(video_count_distribution.index, video_count_distribution.values)\n",
    "    plt.xlabel(\"Num Video CLips/ID\")\n",
    "    plt.ylabel(\"Individuals\")\n",
    "    plt.title(f\"{d}: Number of Video CLips per ID\")\n",
    "    plt.xticks(video_count_distribution.index)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Video Count Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_videos = df_combined.drop_duplicates(subset=[\"GROUP\", \"ID\", \"CAM\", \"DATE\"])\n",
    "videos_per_id = unique_videos.groupby([\"GROUP\", \"ID\"]).size()\n",
    "video_count_distribution = videos_per_id.value_counts().sort_index()\n",
    "\n",
    "plt.figure(figsize=(5, 2))\n",
    "plt.bar(video_count_distribution.index, video_count_distribution.values)\n",
    "plt.xlabel(\"Num Videos/ID\")\n",
    "plt.ylabel(\"Individuals\")\n",
    "plt.title(\"Complete DS: Number of Videos per ID\")\n",
    "plt.xticks(video_count_distribution.index)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, d in enumerate(dirs):\n",
    "    unique_videos = df[i].drop_duplicates(subset=[\"GROUP\", \"ID\", \"CAM\", \"DATE\"])\n",
    "    videos_per_id = unique_videos.groupby([\"GROUP\", \"ID\"]).size()\n",
    "    video_count_distribution = videos_per_id.value_counts().sort_index()\n",
    "    plt.figure(figsize=(5, 2))\n",
    "    plt.bar(video_count_distribution.index, video_count_distribution.values)\n",
    "    plt.xlabel(\"Num Videos/ID\")\n",
    "    plt.ylabel(\"Individuals\")\n",
    "    plt.title(f\"{d}: Number of Videos per ID\")\n",
    "    plt.xticks(video_count_distribution.index)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Number of Images of Individuals with at least 2 Videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined = pd.concat(df)\n",
    "unique_videos = df_combined.drop_duplicates(subset=[\"GROUP\", \"ID\", \"CAM\", \"DATE\"])\n",
    "\n",
    "videos_per_id = unique_videos[[\"GROUP\", \"ID\"]].copy()\n",
    "videos_per_id = videos_per_id.groupby([\"GROUP\", \"ID\"]).size().reset_index()\n",
    "images_per_video = df_combined[[\"GROUP\", \"ID\"]].copy()\n",
    "images_per_video = images_per_video.groupby([\"GROUP\", \"ID\"]).size()\n",
    "images_per_video.name = \"IMAGES\"\n",
    "\n",
    "video_image_distribution = videos_per_id.join(images_per_video, on=[\"GROUP\", \"ID\"], how=\"inner\")\n",
    "video_image_distribution[\"VIDEOS\"] = video_image_distribution[0]\n",
    "video_image_distribution = video_image_distribution.drop(columns=[0])\n",
    "\n",
    "# plot num_images by number of videos\n",
    "plt.figure(figsize=(5, 5))\n",
    "plt.scatter(video_image_distribution[\"VIDEOS\"], video_image_distribution[\"IMAGES\"])\n",
    "plt.xlabel(\"Num Videos\")\n",
    "plt.ylabel(\"Num Images\")\n",
    "plt.title(\"Complete DS: Num Images by Num Videos\")\n",
    "plt.show()\n",
    "\n",
    "# number of images per video count\n",
    "plt.figure(figsize=(5, 5))\n",
    "plt.bar(video_image_distribution[\"VIDEOS\"].value_counts().index, video_image_distribution.groupby(video_image_distribution[\"VIDEOS\"])[\"IMAGES\"].sum().sort_index().values)\n",
    "plt.xlabel(\"Num Videos\")\n",
    "plt.ylabel(\"Num Images\")\n",
    "plt.title(\"Complete DS: Num Images by Num Videos\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "for i, d in enumerate(dirs):\n",
    "    unique_videos = df[i].drop_duplicates(subset=[\"GROUP\", \"ID\", \"CAM\", \"DATE\"])\n",
    "    videos_per_id = unique_videos[[\"GROUP\", \"ID\"]].copy()\n",
    "    videos_per_id = videos_per_id.groupby([\"GROUP\", \"ID\"]).size().reset_index()\n",
    "    images_per_video = df[i][[\"GROUP\", \"ID\"]].copy()\n",
    "    images_per_video = images_per_video.groupby([\"GROUP\", \"ID\"]).size()\n",
    "    images_per_video.name = \"IMAGES\"\n",
    "    video_image_distribution = videos_per_id.join(images_per_video, on=[\"GROUP\", \"ID\"], how=\"inner\")\n",
    "    video_image_distribution[\"VIDEOS\"] = video_image_distribution[0]\n",
    "    video_image_distribution = video_image_distribution.drop(columns=[0])\n",
    "    # plot num_images by number of videos\n",
    "    plt.figure(figsize=(5, 5))\n",
    "    plt.scatter(video_image_distribution[\"VIDEOS\"], video_image_distribution[\"IMAGES\"])\n",
    "    plt.xlabel(\"Num Videos\")\n",
    "    plt.ylabel(\"Num Images\")\n",
    "    plt.title(f\"{d}: Num Images by Num Videos\")\n",
    "    plt.show()\n",
    "    \n",
    "    plt.figure(figsize=(5, 5))\n",
    "    plt.bar(video_image_distribution[\"VIDEOS\"].value_counts().index, video_image_distribution.groupby(video_image_distribution[\"VIDEOS\"])[\"IMAGES\"].sum().sort_index().values)\n",
    "    plt.xlabel(\"Num Videos\")\n",
    "    plt.ylabel(\"Num Images\")\n",
    "    plt.title(f\"{d}: Num Images by Num Videos\")\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Number of Images per Video and per Individual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ASSERT: OPENSET\n",
    "from collections import defaultdict\n",
    "\n",
    "combined_ids = df_combined[\"GROUP\"] + df_combined[\"ID\"]\n",
    "all_individuals = set(combined_ids.unique())\n",
    "individual_seen_in = defaultdict(set)\n",
    "print(dirs)\n",
    "for i, d in enumerate(dirs):\n",
    "    print(f\"Processing {d}\")\n",
    "    individuals = set((df[i][\"GROUP\"] + df[i][\"ID\"]).unique())\n",
    "    for ind in individuals:\n",
    "        individual_seen_in[ind].add(d)\n",
    "        \n",
    "for ind, aDir in individual_seen_in.items():\n",
    "    if len(aDir) > 1:\n",
    "        print(f\"{ind} seen in {aDir}\")\n",
    "print(individual_seen_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "df_combined = pd.concat(df)\n",
    "unique_videos = df_combined.drop_duplicates(subset=[\"GROUP\", \"ID\", \"CAM\", \"DATE\"])\n",
    "videos_per_id = unique_videos[[\"GROUP\", \"ID\", \"CAM\", \"DATE\"]].copy().groupby([\"GROUP\", \"ID\"]).size().reset_index()\n",
    "\n",
    "images_per_video = df_combined[[\"GROUP\", \"ID\", \"CAM\", \"DATE\"]].copy()\n",
    "images_per_video = images_per_video.groupby([\"GROUP\", \"ID\", \"CAM\", \"DATE\"]).size()\n",
    "images_per_video.name = \"IMAGES\"\n",
    "\n",
    "images_per_video = images_per_video.reset_index().join(videos_per_id.set_index([\"GROUP\", \"ID\"]), on=[\"GROUP\", \"ID\"], how=\"inner\")\n",
    "images_per_video[\"VIDEOS\"] = images_per_video[0]\n",
    "images_per_video = images_per_video.drop(columns=[0])\n",
    "images_per_video = images_per_video.reset_index()\n",
    "images_per_video[\"COMPLETE_ID\"] = images_per_video[\"GROUP\"] + images_per_video[\"ID\"]\n",
    "images_per_video = images_per_video.drop(columns=[\"GROUP\", \"ID\"])\n",
    "\n",
    "plt.figure(figsize=(5, 5))\n",
    "plt.scatter(images_per_video[\"VIDEOS\"], images_per_video[\"IMAGES\"], c=images_per_video[\"COMPLETE_ID\"].astype(\"category\").cat.codes, cmap=\"tab20\")\n",
    "plt.colorbar()\n",
    "plt.xlabel(\"Num Videos\")\n",
    "plt.ylabel(\"Num Images\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def cluster_videos(df, clip_distance_max=1000): # 1000 boils down to merging all videos in a day\n",
    "    unique_videos = df.drop_duplicates(subset=[\"GROUP\", \"ID\", \"CAM\", \"DATE\", \"CLIP_ID\"])\n",
    "    videos_per_id = unique_videos.groupby([\"GROUP\", \"ID\"]).size().reset_index(name=\"VIDEOS\")\n",
    "    images_per_video = df.groupby([\"GROUP\", \"ID\", \"CAM\", \"DATE\", \"CLIP_ID\"]).size().reset_index(name=\"IMAGES\")\n",
    "    images_per_video = images_per_video.merge(videos_per_id, on=[\"GROUP\", \"ID\"], how=\"inner\")\n",
    "    images_per_video[\"COMPLETE_ID\"] = images_per_video[\"GROUP\"] + images_per_video[\"ID\"].astype(str)\n",
    "    images_per_video.drop(columns=[\"GROUP\", \"ID\"], inplace=True)\n",
    "    \n",
    "    images_per_video.sort_values(by=[\"COMPLETE_ID\", \"CAM\", \"DATE\", \"CLIP_ID\"], inplace=True)\n",
    "    unique_videos_tmp = []\n",
    "\n",
    "    for _, row in images_per_video.iterrows():\n",
    "        complete_id, cam, date, clip_id, images = row[\"COMPLETE_ID\"], row[\"CAM\"], row[\"DATE\"], row[\"CLIP_ID\"], row[\"IMAGES\"]\n",
    "        found = False\n",
    "        \n",
    "        for video in unique_videos_tmp:\n",
    "            if video[\"COMPLETE_ID\"] == complete_id and video[\"CAM\"] == cam and video[\"DATE\"] == date:\n",
    "                if int(clip_id) - int(video[\"CLIP_ID_LAST\"]) <= clip_distance_max:\n",
    "                    video[\"CLIP_ID_LAST\"] = clip_id\n",
    "                    video[\"IMAGES\"] += images\n",
    "                    found = True\n",
    "                    break\n",
    "        \n",
    "        if not found:\n",
    "            unique_videos_tmp.append({\n",
    "                \"COMPLETE_ID\": complete_id,\n",
    "                \"CAM\": cam,\n",
    "                \"DATE\": date,\n",
    "                \"CLIP_ID_FIRST\": clip_id,\n",
    "                \"CLIP_ID_LAST\": clip_id,\n",
    "                \"IMAGES\": images\n",
    "            })\n",
    "    \n",
    "    return pd.DataFrame(unique_videos_tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_knn_crossencounter(df, class_min=5):\n",
    "    for i, row in df.iterrows():\n",
    "        num_val = 0\n",
    "        for j, row2 in df.iterrows():\n",
    "            if i != j and row[\"COMPLETE_ID\"] == row2[\"COMPLETE_ID\"]: # videos for the same individual\n",
    "                num_val += row2[\"IMAGES\"]\n",
    "        if num_val < class_min:\n",
    "            df.drop(i, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, directory in enumerate(dirs):\n",
    "    df_current = df[i]\n",
    "    images_per_video = cluster_videos(df_current)\n",
    "    \n",
    "    video_counts = images_per_video.groupby(\"COMPLETE_ID\").size().reset_index(name=\"VIDEOS\")\n",
    "    images_per_video = images_per_video.merge(video_counts, on=\"COMPLETE_ID\", how=\"inner\")\n",
    "    filter_knn_crossencounter(images_per_video, 3)\n",
    "    # print(sum(images_per_video[\"IMAGES\"]))\n",
    "    print(f\"{directory}: Has {sum(images_per_video['IMAGES'])} images for {images_per_video['COMPLETE_ID'].nunique()} individuals\")\n",
    "    \n",
    "    plt.figure(figsize=(5, 5))\n",
    "    plt.grid(True)\n",
    "    jitter = np.random.normal(0, 0.1, images_per_video.shape[0])\n",
    "    plt.scatter(images_per_video[\"VIDEOS\"] + jitter, images_per_video[\"IMAGES\"], \n",
    "                c=images_per_video[\"COMPLETE_ID\"].astype(\"category\").cat.codes, cmap=\"tab20\", alpha=0.8, s=100, edgecolors=\"black\")\n",
    "    \n",
    "    handles = [\n",
    "        plt.Line2D([0], [0], marker=\"o\", color=\"w\", \n",
    "                   markerfacecolor=plt.cm.tab20.colors[i % len(plt.cm.tab20.colors)], label=complete_id) \n",
    "        for i, complete_id in enumerate(images_per_video[\"COMPLETE_ID\"].unique())\n",
    "    ]\n",
    "    plt.legend(handles=handles, bbox_to_anchor=(1.05, 1), loc=\"upper left\")\n",
    "    \n",
    "    plt.xticks(np.arange(0, images_per_video[\"VIDEOS\"].max() + 1, 1))\n",
    "    plt.yticks(np.arange(0, images_per_video[\"IMAGES\"].max() + 1, 2))\n",
    "    plt.xlabel(\"Num Videos\")\n",
    "    plt.ylabel(\"Num Images\")\n",
    "    plt.title(f\"{directory}: Num Images by Num Videos\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Crossencounter KNN with 5 random choices of samples -- TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Number of Cameras per Individual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, d in enumerate(dirs):\n",
    "    unique_videos = df[i].drop_duplicates(subset=[\"GROUP\", \"ID\", \"CAM\"])\n",
    "    videos_per_id = unique_videos.groupby([\"GROUP\", \"ID\"]).size()\n",
    "    video_count_distribution = videos_per_id.value_counts().sort_index()\n",
    "    plt.figure(figsize=(5, 2))\n",
    "    plt.bar(video_count_distribution.index, video_count_distribution.values)\n",
    "    plt.xlabel(\"Num Cam/ID\")\n",
    "    plt.ylabel(\"Individuals\")\n",
    "    plt.title(f\"{d}: Number of Cameras per ID\")\n",
    "    plt.xticks(video_count_distribution.index)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Images per Camera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, d in enumerate(dirs):\n",
    "    unique_videos = df[i].drop_duplicates(subset=[\"GROUP\", \"ID\", \"CAM\", \"DATE\"])\n",
    "    images_per_camera = unique_videos.groupby(\"CAM\").size()\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.bar(images_per_camera.index, images_per_camera.values)\n",
    "    plt.xlabel(\"Camera ID\")\n",
    "    plt.ylabel(\"Images\")\n",
    "    plt.title(f\"{d}: Images/Camera\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Individuals per Camera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, d in enumerate(dirs):\n",
    "    unique_videos = df[i].drop_duplicates(subset=[\"GROUP\", \"ID\", \"CAM\", \"DATE\"])\n",
    "    individuals_per_camera = unique_videos.groupby([\"CAM\", \"GROUP\", \"ID\"]).size().reset_index().groupby(\"CAM\").size()\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.bar(individuals_per_camera.index, individuals_per_camera.values)\n",
    "    plt.xlabel(\"Camera ID\")\n",
    "    plt.ylabel(\"Individuals\")\n",
    "    plt.title(f\"{d}: Individuals/Camera\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combined\n",
    "df_combined = pd.concat(df)\n",
    "unique_videos = df_combined.drop_duplicates(subset=[\"GROUP\", \"ID\", \"CAM\", \"DATE\"])\n",
    "images_per_camera = unique_videos.groupby(\"CAM\").size()\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.bar(images_per_camera.index, images_per_camera.values)\n",
    "plt.xlabel(\"Camera ID\")\n",
    "plt.ylabel(\"Images\")\n",
    "plt.title(\"Combined: Images/Camera\")\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()\n",
    "\n",
    "# make this plot a histogram with bins of 10 images per camera and show the number of cameras in each bin\n",
    "# center the bins\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.hist(images_per_camera, bins=range(0, 80, 5), align=\"left\", rwidth=0.9)\n",
    "plt.xticks(ticks=range(0, 80, 5), labels=[f\"{i} - {i+5}\" for i in range(0, 80, 5)], rotation=90)\n",
    "plt.xlabel(\"Images/Camera\")\n",
    "plt.ylabel(\"Cameras\")\n",
    "plt.title(\"Combined: Images/Camera\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Individuals per Group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, d in enumerate(dirs):\n",
    "    unique_videos = df[i].drop_duplicates(subset=[\"GROUP\", \"ID\", \"CAM\", \"DATE\"])\n",
    "    unique_individuals_per_group = unique_videos.groupby([\"GROUP\", \"ID\"]).size().reset_index().groupby(\"GROUP\").size()\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.bar(unique_individuals_per_group.index, unique_individuals_per_group.values)\n",
    "    plt.xlabel(\"Group ID\")\n",
    "    plt.ylabel(\"Individuals\")\n",
    "    plt.title(f\"{d}: Individuals/Group\")\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Images per Category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorize_id(id_):\n",
    "    id_num = int(id_)\n",
    "    if id_num == 0:\n",
    "        return \"Silverback\"\n",
    "    elif 1 <= id_num <= 19:\n",
    "        return \"Adult female\"\n",
    "    elif 20 <= id_num <= 39:\n",
    "        return \"Blackback\"\n",
    "    elif 40 <= id_num <= 59:\n",
    "        return \"Adolescent & Juvenil\"\n",
    "    elif 60 <= id_num <= 79:\n",
    "        return \"Infant\"\n",
    "    else:\n",
    "        return \"Unknown\"\n",
    "\n",
    "for i, d in enumerate(dirs):\n",
    "    unique_individuals = df[i].drop_duplicates(subset=[\"GROUP\", \"ID\"]).copy()\n",
    "    # filter out non numeric IDs\n",
    "    unique_individuals = unique_individuals[unique_individuals[\"ID\"].str.isnumeric()]\n",
    "    \n",
    "    # Categorize each ID and add to the DataFrame using assign()\n",
    "    unique_individuals = unique_individuals.assign(Type=unique_individuals[\"ID\"].apply(categorize_id))\n",
    "    \n",
    "    # Calculate the number of each type\n",
    "    type_distribution = unique_individuals[\"Type\"].value_counts().sort_index()\n",
    "    \n",
    "    \n",
    "    # Plot the distribution of types\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.bar(type_distribution.index, type_distribution.values)\n",
    "    plt.xlabel(\"Type\")\n",
    "    plt.ylabel(\"Number of Individuals\")\n",
    "    plt.title(f\"{d}: Types of Individuals\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resolution of Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the resolution of all combined images \n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "img_sizes = []\n",
    "for row in df_combined.itertuples():\n",
    "    img = Image.open(os.path.join(dir_path, row[6]))\n",
    "    img_sizes.append(img.size)\n",
    "        \n",
    "len(img_sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a matrix histogram of the image sizes (width x height)\n",
    "from matplotlib.colors import LogNorm\n",
    "import numpy as np\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "amounts_x, amounts_y = [x[0] for x in img_sizes], [x[1] for x in img_sizes]\n",
    "norm = LogNorm(vmax=1000)\n",
    "plt.hist2d(amounts_x, amounts_y, bins=range(0, 500, 50), cmap=\"Greens\", norm=norm)\n",
    "for i in range(0, 450, 50):\n",
    "    for j in range(0, 450, 50):\n",
    "        plt.text(i+25, j+25, f\"{len([1 for x in img_sizes if i <= x[0] < i+50 and j <= x[1] < j+50])}\", color=\"black\", ha=\"center\", va=\"center\")\n",
    "plt.xlabel(\"Width\")\n",
    "plt.ylabel(\"Height\")\n",
    "plt.title(\"Image Sizes\")\n",
    "# plt.colorbar()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot one low mid and high resolution image\n",
    "very_low_res = [x for x in img_sizes if x[0] < 50 and x[1] < 50][1]\n",
    "low_res = [x for x in img_sizes if 50 <= x[0] < 100 and 50 <= x[1] < 100][0]\n",
    "mid_res = [x for x in img_sizes if 100 <= x[0] < 200 and 100 <= x[1] < 200][0]\n",
    "high_res = [x for x in img_sizes if x[0] > 200 and x[1] > 200][21]\n",
    "\n",
    "plt.figure(figsize=(20, 5))\n",
    "plt.subplot(1, 4, 1)\n",
    "plt.imshow(Image.open(os.path.join(dir_path, df_combined.iloc[img_sizes.index(very_low_res)][\"FILENAME\"])))\n",
    "plt.title(f\"Very Low Resolution: {very_low_res}\")\n",
    "plt.axis(\"off\")\n",
    "plt.subplot(1, 4, 2)\n",
    "plt.imshow(Image.open(os.path.join(dir_path, df_combined.iloc[img_sizes.index(low_res)][\"FILENAME\"])))\n",
    "plt.title(f\"Low Resolution: {low_res}\")\n",
    "plt.axis(\"off\")\n",
    "plt.subplot(1, 4, 3)\n",
    "plt.imshow(Image.open(os.path.join(dir_path, df_combined.iloc[img_sizes.index(mid_res)][\"FILENAME\"])))\n",
    "plt.title(f\"Mid Resolution: {mid_res}\")\n",
    "plt.axis(\"off\")\n",
    "plt.subplot(1, 4, 4)\n",
    "plt.imshow(Image.open(os.path.join(dir_path, df_combined.iloc[img_sizes.index(high_res)][\"FILENAME\"])))\n",
    "plt.title(f\"High Resolution: {high_res}\")\n",
    "plt.axis(\"off\")\n",
    "plt.show() "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
